{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yQD7db2DU812"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "# Load dataset\n",
        "max_features = 20000  # Number of words to consider as features\n",
        "maxlen = 80  # Cut texts after this number of words\n",
        "\n",
        "# Load IMDB data\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Preprocess data: pad sequences to ensure each input sequence has the same length\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divide Data into Training and Testing sets\n"
      ],
      "metadata": {
        "id": "CBHv1sj1WAJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "# Load dataset\n",
        "max_features = 20000  # Number of words to consider as features\n",
        "maxlen = 80  # Cut texts after this number of words\n",
        "\n",
        "(X, y), (_, _) = imdb.load_data(num_words=max_features)  # Load full dataset\n",
        "\n",
        "# Preprocess data: pad sequences to ensure each input sequence has the same length\n",
        "X = sequence.pad_sequences(X, maxlen=maxlen)\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Now you can proceed with model training and evaluation\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Testing set size: {len(X_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVMMZIbEWPva",
        "outputId": "5887fc58-af93-4982-b2c3-4c8591423890"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 20000\n",
            "Testing set size: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the Gated Recurrent Units(GRU)Model\n"
      ],
      "metadata": {
        "id": "hz2OTNiNWZvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128, input_length=maxlen))  # Embedding layer for word embeddings\n",
        "model.add(GRU(128, return_sequences=False))  # GRU layer with 128 units\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "XMZBBSbCWnfV",
        "outputId": "2ffcd477-e667-4f0c-e611-a20e1cfd0c43"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the GRU Model\n"
      ],
      "metadata": {
        "id": "-N6rrlDKWvQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the GRU model\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gzPqR5jW2Eq",
        "outputId": "a8bae09a-f4b9-45fe-937e-a5e7c6ecf2e0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 154ms/step - accuracy: 0.6816 - loss: 0.5708 - val_accuracy: 0.8335 - val_loss: 0.3761\n",
            "Epoch 2/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 151ms/step - accuracy: 0.9015 - loss: 0.2508 - val_accuracy: 0.8248 - val_loss: 0.3888\n",
            "Epoch 3/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 148ms/step - accuracy: 0.9592 - loss: 0.1198 - val_accuracy: 0.8223 - val_loss: 0.5056\n",
            "Epoch 4/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 144ms/step - accuracy: 0.9868 - loss: 0.0435 - val_accuracy: 0.8240 - val_loss: 0.6041\n",
            "Epoch 5/5\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 139ms/step - accuracy: 0.9924 - loss: 0.0260 - val_accuracy: 0.8220 - val_loss: 0.8589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Generation using the Trained Model\n"
      ],
      "metadata": {
        "id": "J6mIfDeGX2aD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Assuming reverse_word_map is a dictionary mapping word indices back to words\n",
        "\n",
        "# Function to generate text\n",
        "def generate_text(seed_text, model, max_sequence_len, reverse_word_map):\n",
        "    for _ in range(50):  # Number of words to generate\n",
        "        token_list = text_to_word_sequence(seed_text)  # Tokenize seed text\n",
        "        token_list = [reverse_word_map.get(word, 0) for word in token_list]  # Convert words to indices\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')  # Pad sequences\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted = np.argmax(predicted_probs, axis=-1)\n",
        "\n",
        "        # Handle KeyError by using <UNK> for unknown words\n",
        "        next_word = reverse_word_map.get(predicted[0], \"<UNK>\")\n",
        "\n",
        "        seed_text += \" \" + next_word  # Append predicted word to seed text\n",
        "    return seed_text\n",
        "\n",
        "# Example usage of generate_text\n",
        "word_index = imdb.get_word_index()  # Original word to index mapping from IMDB dataset\n",
        "reverse_word_map = {index: word for word, index in word_index.items()}  # Reverse map\n",
        "\n",
        "# Ensure the special tokens exist in reverse_word_map\n",
        "reverse_word_map[0] = \"<PAD>\"  # Padding token\n",
        "reverse_word_map[1] = \"<START>\"  # Start token (depends on dataset)\n",
        "reverse_word_map[2] = \"<UNK>\"  # Unknown token\n",
        "\n",
        "# Assuming 'model' and 'maxlen' are already defined and trained\n",
        "generated_text = generate_text(\"This movie\", model, maxlen, reverse_word_map)\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYe0xqwubStn",
        "outputId": "6ed111be-819f-41e9-cddc-3e3540102409"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This movie <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Models's Accuracy\n"
      ],
      "metadata": {
        "id": "bcP1A4GXYlsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Le_dyRPbcs6",
        "outputId": "7706e849-a3ae-4cbe-96f0-96848bb5b82c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.5119 - loss: 0.6929\n",
            "Test Accuracy: 51.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare accuracy of Long sort term memory and Gated recurrent Unit models for text generation using data from tensorflow.keras.datasets.\n"
      ],
      "metadata": {
        "id": "ighwykF5cGEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Preprocess the Data"
      ],
      "metadata": {
        "id": "39wx4Hy2cQ7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "# Load dataset\n",
        "max_features = 20000  # Number of words to consider as features\n",
        "maxlen = 80  # Cut texts after this number of words\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Preprocess data: pad sequences to ensure each input sequence has the same length\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n"
      ],
      "metadata": {
        "id": "NYLa9UURcaAm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TWNN5um1coHW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the LSTM Model\n"
      ],
      "metadata": {
        "id": "lQHbGyyJchQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Build the LSTM model\n",
        "def create_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128, input_length=maxlen))\n",
        "    model.add(LSTM(128, return_sequences=False))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "lstm_model = create_lstm_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtABI6wccj-8",
        "outputId": "2ca9e140-c261-438d-990e-40bfb0cbbd12"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the GRU Model\n"
      ],
      "metadata": {
        "id": "QS_xqKuYcuCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GRU\n",
        "\n",
        "# Build the GRU model\n",
        "def create_gru_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128, input_length=maxlen))\n",
        "    model.add(GRU(128, return_sequences=False))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "gru_model = create_gru_model()\n",
        "\n"
      ],
      "metadata": {
        "id": "-4c2J7wgcwKe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Both Models"
      ],
      "metadata": {
        "id": "8C1NSb9yfz37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train with LSTM model"
      ],
      "metadata": {
        "id": "bQ-4CiYqgPYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the LSTM model\n",
        "lstm_history = lstm_model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMFnw3MlgFo1",
        "outputId": "bb68800b-c19b-4d58-ff95-7d0c0223ec16"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 170ms/step - accuracy: 0.9900 - loss: 0.0361 - val_accuracy: 0.8072 - val_loss: 0.6997\n",
            "Epoch 2/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 168ms/step - accuracy: 0.9911 - loss: 0.0290 - val_accuracy: 0.8156 - val_loss: 0.7399\n",
            "Epoch 3/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 166ms/step - accuracy: 0.9958 - loss: 0.0144 - val_accuracy: 0.7966 - val_loss: 1.0219\n",
            "Epoch 4/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 164ms/step - accuracy: 0.9972 - loss: 0.0129 - val_accuracy: 0.8206 - val_loss: 1.0940\n",
            "Epoch 5/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 164ms/step - accuracy: 0.9957 - loss: 0.0139 - val_accuracy: 0.8176 - val_loss: 1.0708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train with GRU model"
      ],
      "metadata": {
        "id": "r3NYyqnzgW64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the GRU model\n",
        "gru_history = gru_model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cyhnvd3VgMNT",
        "outputId": "ae171077-e197-46da-f633-2925635e2ee9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 143ms/step - accuracy: 0.7039 - loss: 0.5341 - val_accuracy: 0.8246 - val_loss: 0.3833\n",
            "Epoch 2/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 138ms/step - accuracy: 0.9113 - loss: 0.2300 - val_accuracy: 0.8370 - val_loss: 0.4038\n",
            "Epoch 3/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 143ms/step - accuracy: 0.9587 - loss: 0.1176 - val_accuracy: 0.8310 - val_loss: 0.4583\n",
            "Epoch 4/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 136ms/step - accuracy: 0.9822 - loss: 0.0533 - val_accuracy: 0.8236 - val_loss: 0.5626\n",
            "Epoch 5/5\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 138ms/step - accuracy: 0.9915 - loss: 0.0288 - val_accuracy: 0.8122 - val_loss: 0.7448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate and Compare Accuracy\n"
      ],
      "metadata": {
        "id": "qcz53wAugc21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate LSTM model\n",
        "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test, y_test)\n",
        "print(f\"LSTM Test Accuracy: {lstm_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Evaluate GRU model\n",
        "gru_loss, gru_accuracy = gru_model.evaluate(X_test, y_test)\n",
        "print(f\"GRU Test Accuracy: {gru_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Compare the accuracies\n",
        "if lstm_accuracy > gru_accuracy:\n",
        "    print(\"LSTM performed better.\")\n",
        "else:\n",
        "    print(\"GRU performed better.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r57YYZ3pggFl",
        "outputId": "87dd99a0-c847-4375-bd2a-c2c3ea714baf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 48ms/step - accuracy: 0.7982 - loss: 0.7346\n",
            "LSTM Test Accuracy: 80.11%\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.8197 - loss: 0.7604\n",
            "GRU Test Accuracy: 82.22%\n",
            "GRU performed better.\n"
          ]
        }
      ]
    }
  ]
}